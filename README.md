# clothes-recognition
My course work consisting of image parsing, creating own model and classifing the photo of clothes.


Федеральное государственное образовательное бюджетное учреждение  высшего профессионального образования «Финансовый университет при Правительстве Российской Федерации»
Департамент анализа данных, принятия решений и финансовых технологий
Курсовая работа
(По дисциплине «Машинное обучение»)
 на тему:
«Машинное обучение в задачах распознавания товаров сектора экономики на фотографии (на примере модной индустрии)»





Выполнила:
Студентка группы ПМ3-3
Лутфуллина A.A.

Руководитель:
Доцент к/н
Кочкаров Р.А.


Оглавление
Введение	3
1. Предварительный анализ исходных данных	4
1.1. Методы распознавания объектов на изображении	4
1.2. Анализ предметной области	10
1.3. Постановка задачи	11
2. Исследование и построение решения задачи	11
2.1. Алгоритм	11
2.2. Техническая реализация	14
3. Апробация	16
3.1. Решение на реальных данных	16
3.2. Полученные результаты	18
3.3. Анализ имеющихся результатов	18
Заключение	18
Список использованных источников	18
 











Введение 
Изменения, происходящие в сферах общественной жизни людей, таких как экономика, политика, культура, наука и др., отражаются на тенденциях в области ритейла, которые могут проявляться как в поведении покупателей, так в способах организации торгово-технологических процессов . При этом в большей мере на покупательское поведение влияет экономическая ситуация страны. Так, более высокий уровень жизни влечет за собой большее потребление непродовольственных товаров, включая одежду, обувь и аксессуары.  Кроме того, в современном покупательском поведении проявляется тенденция на более тесную взаимосвязь реальных и виртуальных магазинов. Рынок модной индустрии все чаще демонстрирует новые форматы магазинов, решений мерчендайзинга и возможности для продаж посредством электроники. Таким образом, область fashion-ритейла является перспективным направлением для внедрения разработок машинного обучения, в том числе нейронных сетей. Нейронные сети, представляющие собой технологии глубинного обучения, аналогичны работе человеческих нейронов. Они, в процессе получения новых данных, обучаются и корректируют ошибки, допуская их все меньше ввиду полученного опыта. Данная технология воплощена в сфере модной индустрии посредством системы мобильного распознавания. При обнаружении пользователем понравившегося ему товара, он загружает его фото в специализированное на распознавании предметов приложение и с лёгкостью находит похожие товары в интернет-магазинах, при этом можно делать уточнения в поиске и мгновенно его приобретать, что значительно экономит время пользователю и деньги за аренду помещения продавцу, следовательно, совершенствование и развитие данного направления актуально и полезно для как для развития экономики, так и человечества в целом, поэтому цель работы – исследовать и реализовать распознавание объектов на фотографиях, в нашем случае предметов одежды. 
1. Предварительный анализ исходных данных 
1.1. Методы распознавания объектов на изображении
Существует несколько основных методов применяемых для распознавания объектов на изображении :
	Эвристические методы
	Полная эвристическая модель
	Поиск по характерным инвариантным признакам
	Метод сравнения с шаблоном 
	Методы обучения по прецедентам 
Рассмотрим каждый метод подробнее.
У истоков машинного обучения стояли эвристические методы, являясь одними из первых в распознавании по изображению, они просты по своей сути и быстры в работе. Однако имеют недостатки, которые заключаются в жестко запрограммированных правилах при отборе заданных объектов. Это лишает данный метод гибкости и устойчивости, что приводит к узкому кругу реализуемых задач. Таковыми являются поиск объектов при точно заданном освещении или ракурсе. Полная эвристическая модель строится на описании всех правил, которые бы описывали изображение требуемого объекта, после чего производится сам процесс обнаружения. Чуть более гибким является поиск по характерным инвариантным признакам. В данном методе задаётся не полное описание объекта, а лишь характерные его признаки, что позволяет проводить поиск при различных искажениях объекта на изображении.
Куда более универсальным является метод сравнения с шаблоном. В его основе так же лежит создание шаблона с изображением объекта в целом или его характерных признаков, при этом вводится функция, проверяющая на соответствие. Для высокой точности и низкого уровня сбоев необходимо чтобы этот шаблон был максимально полно задан, в том числе имел сложную структуру, допускал преобразования и деформации, которые бы способствовали поиску при изменениях освещенности или искажении изображения. Благодаря этому, данный метод может применяться в системе распознавания на видео, где при появлении объекта в кадре, он инициализируется, после чего существующий шаблон корректируется и уточняется в последствии. 
Наиболее распространен метод обучения по прецедентам (обучение с учителем), состоящий в автоматическом построении модели на основе уже имеющихся изображений, набор которых создается заранее и включает в себя прецеденты с информацией о наличии или отсутствии на них требуемого объекта.   Тогда все сводится к задаче классификации (проверке принадлежности изображения к классу изображений требуемого объекта), исходя из известных наблюдений (вектора признаков), получаемые из изначального изображения преобразованием, которое отображает изображения в пространство действительных векторов.  Таким образом можно говорить о существовании двух модулей системы: Первый – преобразование изображения в вектор признаков, второй – классификации. Основная задача первого модуля –представление в виде числового вектора изображения как можно более полно, информативно, масштабируемо и быстро, для того, чтобы это было максимально удобно для модуля классификации. В котором, на основании имеющегося вектора признаков, необходимо проверить принадлежит ли изображение к классу изображений с требуемым объектом.
Ввиду того, что в реальных системах метод классификации по прецедентам является наиболее интересным с точки зрения обобщенности и многообещающих результатов, полагаю целесообразным проанализировать различные подходы данного метода. Однако прежде введем базовые понятия:
Пусть вектор признаков x∈X⊆R^n – это вектор содержащий описание объекта, (предоставляется модулем преобразований, который описан выше). K_y={x∈X ┤|  y^* (x)=y}-Класс множества X. 
y∈Y⊆Z-множество маркеров класса, при бинарной классификации
Y={-1,+1},   в нашем случае под этим подразумевается присутствие или отсутствие распознаваемого объекта на изображении. 
X □(→┴y^*  )  Y-отображение определенное для всех  x∈X,  задающих разбиение X на подмножества K_y.
Набор прецедентов T=(x_1,y_1 ),… ,(x_l,y_l )  для которых y^* (x_i )=y_i-  называется обучающей выборкой, которая является по своей сути информацией об отображении X □(→┴y^*  )  Y.
Чтобы использовать алгоритм классификации и распознавания принимаем гипотезу о том, что множество X □(×)  Y-  вероятностное пространство с мерой P.      А (x_1,y_1 ),… ,(x_l,y_l )  случайны   и   независимы   при  P   распределении. 
Задачей классификации является построение функции-классификатора F(x), которая бы приближала отображение y^* основываясь на T=(x_1,y_1 ),… ,(x_l,y_l ). 
При этом P(F(x)≠y  ┤|(x,y)∈T), показывающее вероятность неверной работы функции-классификатора для вектора  x будем называть эмпирическим риском. А P( F(x)≠y  ┤|  x∈X ), показывающее что классификатор ошибется на данных не входивших в обучающую выборку – общим риском.
Если классификатор эффективно уменьшает общий риск, оцененный на контрольной выборке, то он обладает хорошей обобщающей способностью. При этом если он при уменьшении эмпирического риска способствует возрастанию обобщающего, то классификатор склонен к переобучению, этому может способствовать шум, невыполнение принятой гипотезы или высокая сложность функции F(x). 
Рассмотрим основные классификаторы для распознавания объектов на изображении при обучении по прецедентам. 
Принцип максимума апостериорной вероятности, с решающим правилом F(x)=arg  max┬(y∈Y)⁡〖〖P(K〗_y  | x)〗=arg  max┬(y∈Y)⁡〖 p_y (x) P_y  〗  , является оптимальным при минимизации общего риска , ввиду отсутствия чёткой геометрической структуры разделяющей поверхности, и основывается на следующих гипотезах:
	Множество X □(×)  Y-  вероятностное пространство с мерой P. При этом набор прецедентов в обучающей выборке (x_1,y_1 ),… ,(x_l,y_l )  случаен   и   независим   при  P   распределении.
	Известны априорные вероятности – вероятности появления объектов каждого класса P_y=〖P(K〗_y),y∈Y.
	Известны функции правдоподобия – плотности распределения каждого класса p_y (x)=〖p(x ┤|  K〗_y),y∈Y.
Однако последние две гипотезы редко выполняются на реальных данных, поэтому часто используется «наивный» Байесовский метод, который аппроксимирует вышеизложенный подход. Его отличие заключается в эмпирическом нахождении плотности распределения вероятностей при независимых компонентах вектора признаков, а компактное представление этих векторов, решает проблему слабой обусловленности.
Также, для решения проблемы строгих гипотез принципа максимума апостериорной вероятности, существуют Байесовские сети или так называемые сети доверия, подход которых совмещает в себе Байесовский метод и теорию графов. То есть компоненты вектора признаков записываются в вершины направленного ациклического графа, а причинно-следственные связи представляются в виде соединяющих их дуг, которые строятся за счет выявления корреляции между вершинами. Для решения существующей проблемы плохой обусловленности размерность вектора признаков сокращают, однако это ухудшает обобщающую способность. 
Другим методом классификации являются классические нейронные сети. Их главное преимущество – практически безграничная гибкость. Нейросети за счет нейронов (параллельно работающих функциональных элементов) последовательно преобразуют сигнал, стремясь при этом минимизировать локальные среднеквадратические ошибки, что зачастую может приводить к переобучению. Итог работы нейросети – разделяющая пространство признаков Х на классы поверхность, которая состоит из множества гиперплоскостей. В основе работы систем, использующих нейронные сети для распознавания объектов на изображениях, лежит иерархическая архитектура. Так, первым этапом происходит обработка вектора признаков грубой сетью, у которой высокий уровень ошибок 2-ого рода. А затем, после отсева векторов без наличия объектов, оставшиеся вектора корректируются за счет более тонкой и медленной сети. Помимо этого, существуют сверточные нейронные сети, их архитектура заранее нацелена на получение на вход изображений, свойства входных данных позволяют эффективнее реализовать функцию прямого распространения, а также общее количество параметров сети, за счет чего процесс распознавания становится быстрее.
Существует особый вид нейронной сети – SNoW (разреженная просеивающая сеть). Ввиду того, что вектор признаков полагается в данном случае бинарным, сеть состоит из 2-х линейных нейронов, связанных с его компонентами. Так, SNoW геометрически представляется в виде двух гиперплоскостей в пространстве векторов признаков. А вектор относится к классу, гиперплоскость которого ближе всего. 
Следующим методом, который успешно был применен в задаче распознавания объектов на изображении является метод опорных векторов.  Классический алгоритм заключается в нахождении по прецедентам выпуклой оболочки классов, после чего равноудаленно от них строится линейная разделяющая поверхность – гиперплоскость. Исходя из этого можно считать найденную гиперплоскость оптимальной относительно общего риска. При линейно неразделимых классах применяется ядровое преобразование, которое проецирует пространство Х в пространство большей размерности, и создает линейную разделяющую поверхность, которая является нелинейной в исходном пространстве. Построение классификатора в методе опорных векторов происходит за счет решения задач квадратичного программирования оптимизационными методами, находя при этом глобальный экстремум.  
Последним рассмотренным нами методом будет classifier boosting – метод усиления слабых классификаторов. Он заключается в объединении воедино (в так называемый комитет) примитивных классификаторов. Возможность добавления слабого классификатора в комитет позволяет итеративно (используя жадный алгоритм) минимизировать выпуклый функционал ошибки. После чего готовый комитет создает линейную классификацию из выходных значений примитивных классификаторов. Специально для задачи распознавания объектов был разработан каскадный подход, работающий по принципу последовательный приближений. Алгоритмом AdaBoost строятся комитеты, которые составляют ступени каскада, и вектор признаков классифицируется как искомый объект, только в случае если все ступени каскада это подтвердили.
1.2. Анализ предметной области 
В рамках работы требуется реализовать алгоритм по распознаванию предметов одежды на фотографиях с их дальнейшей классификацией на заданные категории. В качестве категорий возьмем за основу категории одного из лучших онлайн-магазинов одежды в России – Lamoda.ru. На данном сайте они представлены следующим образом:  
	Блузы и рубашки
	Брюки
	Верхняя одежда
	Джемперы, свитеры и кардиганы
	Джинсы
	Комбинезоны
	 Купальники и пляжная одежда
	 Нижнее белье
	 Носки, чулки и колготки
	Пиджаки и костюмы
	 Платья и сарафаны
	Толстовки и свитшоты
	 Топы и майки
	 Туники
	 Футболки и поло
	 Шорты
	 Юбки
На вход будут поступать реальные фотографии одежды, а также изображения, полученные из общедоступных источников. Таким образом, изображения могут быть не всегда в хорошем качестве, с различными шумами, и искажениями: с неравномерным распределением света, с поворотом камеры, с горизонтальными или вертикальными сдвигами и тому подобное. Кроме того, ввиду возможных ограничений компьютерных мощностей у пользователей, необходимо, чтобы хранение извлечённых в процессе работы признаков занимало не много памяти и имело достаточно быструю скорость обучения.
Исходя из этого, наиболее подходящим для наших целей методом, можно полагать, являются сверточные нейронные сети – один из лучших алгоритмов по распознаванию и классификации на изображении. 

1.3. Постановка задачи 
Так, основная задача в рамках работы – исследовать алгоритм работы сверточных нейронных сетей, после чего реализовать данный алгоритм и проверить решение на реальных данных.  Это позволит получить представление о распознавании объектов на изображении. Выявление тех или иных недочетов и преимуществ даст возможность проанализировать эффективность выбранных методов и принять во внимание возможность модификации процесса, для дальнейшей работы в заданном направлении.

2. Исследование и построение решения задачи 
2.1. Алгоритм  
Для начала рассмотрим подробнее архитектуру сверточных нейронных сетей:
 
Рис.1 Архитектура СНС
На рисунке слева направо изображены следующие типы слоев СНС:
Сверточный слой, производящий свертку входящей матрицы с ядром свертки, количество которых равно количеству карт признаков. 
Подвыборочный (слой пулинга или субдискретизирующий слой) сжимает полученную свернутую матрицу для понижения размера данных и выделения низкоуровневых признаков. Для сжатия чаще всего применяется среднее арифметическое или максимальное значение по окну.
Полносвязный слой, получающий от предыдущих слоев одномерный вектор – матрицу, записанную поэлементно в строку. 
При классификации объектов на изображении входной слой является сверточным, затем чередуются сверточные и подвыборочные слои, после чего завершают все полносвязные слои. Конечная часть сверточных нейросетей прдставляет собой полносвязный перцептрон.
Сигнал прямо распространяющийся по сети, проходит через сверточный слой и выполняется valid-свертка, при которой ядро накладывается на область матрицы, и они поэлементно перемножаются, после чего находится сумма произведений. Затем ядро смещается слева направо на один элемент, и операция выполняется заново. От каждого элемента полученной матрицы вычисляется функция активации.  При попадании сигнала на слой пулинга матрица разбивается на области, для каждой из которых находится среднее/максимум ее элементов. Далее сигнал преобразуется из двухмерных матриц в одномерные векторы и помещается на полносвязный слой, где каждый нейрон 1-ого слоя связан с каждым нейроном 2-ого слоя, значения которого вычисляются по следующим формулам:
l_2j=F(S_2j ),j= ¯(1..n)  
S_2j=(∑_(i=1)^m▒〖l_1i*ω_ij) 〗-T_2j
где F – значение функции активации от  S_2j – взвешенной суммы;
 l_1i и l_2j – значения i-ого и j-ого нейронов 1-ого и 2-ого слоев нейронов соответственно;
ω_ij – значение связи между i-ым и j-ым нейронами;
T_2j  – значение порога j-ого нейрона второго слоя.
Сверточные нейронные сети обучаются, используя специфическую версию алгоритма обратного распространения ошибки.
Для обучения полносвязных слоев на последнем слое нейронов формируется ошибка равная разности между выходной реакцией сети y и эталоном t:       γ_j=y_j-t_j. Затем изменяются значения весов и порогов: ω_ij (t+1)= ω_ij (t)-αγ_j F^' (S_j ) y_i;    T_j (t+1)= T_j (t)-αγ_j F^' (S_j ),  где α – скорость обучения сети;   t и t+1 – моменты времени до и после изменений; 
Для скрытого слоя i ошибка вычисляется исходя из ошибки следующего за ним слоя j: γ_i= ∑_j▒γ_j  F^' (S_j ) ω_ij
Обучение полносвязных слоев происходит по процедуре Розенблатта, это значит, что скорость обучения постоянна и принимает значения на промежутке (0;1].
При обучении подвыборочного слоя обратное распространение ошибки зависит от функции пулинга, если это среднеарифметическое, то ошибка распространяется равномерно по нейронам блока предыдущего слоя; если это минимум, то нейрону блока, с которого был взят максимум, по блоку присваивается ошибка.
На выходе с выполнением обратной свертки матрица получается большего размера. Затем с матрицей ошибок, повернутой на 180 градусов, происходит свертка входа сверточного слоя. Схема процесса представлени ниже:


 
Рис.2 Схема процесса свертки входа сверточного слоя с матрицей ошибок
Скорость обучения α умножается на полученную матрицу, которую после этого вычитают из ядра свертки данного слоя. Это приводит к изменению весов в ядре свертки сверточного слоя.

2.2. Техническая реализация 
Реализация алгоритма распознавания объектов на изображении осуществляется на ПК с процессором Intel(R), Core(TM) i7-7500U CPU @ 2.70GHz 2.90 GHz. Разработка модели сверточных нейронных сетей производится на языке Python в среде разработки PyCharm.
В своей работе я буду использовать уменьшенный вариант VGGNet (sVGGNet), в которой используются сверточные фильтры 3х3 и сверточные слои чередуются с подвыборочными слоями .
Для начала определим класс sVGGNet и метод сборки, для которого требуются следующие параметры: ширина, высота, глубина (depth=3, ввиду RGB) входных изображений и число классов. Зададим последовательную модель и размер изображений, после чего добавим слои: сверточный слой с 32-мя фильтрами размера 3х3, функцию активации ReLU, так же пакетную нормализацию (Batch Normalization) для масштабирования данных, слои пулинга (3х3 для постепенного уменьшения размера) и метод исключения, деактивирующий в нашем случае 25% случайных нейронов между слоями.
Затем используем сверточный слой, активацию ReLU, опять сверточный и ReLU, и слой пулинга размером 2х2. Это позволяет нам увеличить число фильтров с 32 до 64. После, повторяем проделанное, тем самым увеличивая количество фильтров до 128.  
Завершаем все полносвязными слоями (Dense) с функцией активации ReLU, последний слой соединен с 17-тью выходами, количество которых обусловлено количеством классов. А слой softmax позволяет определить вероятность принадлежности к классу каждой метки.
Теперь, когда sVGGNet определена, можно приступить к обучению сверточной нейронной сети.   После подключения необходимых пакетов мы создаем парсер, запрашивающий в командной строке три аргумента: путь к набору данных, используемых для обучения; директория, где будет храниться обученная модель; путь к бинаризатору меток, который позволяет трансформировать названия классов в вектора и обратно.
Далее зададим количество эпох (Epochs=100 – количество прохождений сети по каждому примеру для обучения), скорость обучения (LR=0,001 – стандартное значение для оптимизатора Adam), размер пакетов (BatchSize=32) и размеры изображения (Image_size=96, 96, 3). 
После перемешивания путей изображений, мы проходимся по каждому из них и считывая приводим к заданному ранее размеру изображения. Эти изображения с помощью функции Керас img_to_array() мы приводим к совместимому с Керасом массиву. Попутно записывая метки изображений в отдельный список. 
Конвертируя имеющийся массив изображений к массиву NumPy, мы масштабируем интенсивности пикселей в диапазон [0, 1]. А метки конвертируем из целых чисел в векторы за счет функции LabelBinarizer() из библиотеки scikit-learn.  
В машинном обучении общепринятой практикой является разделение данных на тестовую и обучающие выборки. В нашей работе мы разделили их в соотношении 80/20.
При сборке модели используем метод sVGGNet.build для передачи необходимых параметров. Компилируем модель с помощью оптимизатора Adam с указанной выше скоростью, а также категориальной кросс-энтропии в качестве функции потерь. Мы используем категориальную кросс-энтропию, а не бинарную, так как в задаче классификации используется более двух классов.
Так как мы будем работать с ограниченным количеством изображений резонно будет добавить генератор данных, использующий имеющиеся изображения, поворачивая их, сдвигая, обрезая или увеличивая. Дополнение данных повышает эффективность модели и позволяет избежать переобучение. 
Далее, для обучения нейросети вызываем метод model.fit_generator. Этот метод используется в случае дополненных данных. Генератор, используя заданные ранее настройки, будет создавать партии дополненных данных.
Сохраним полученную модель и бинаризатор меток. В завершении, оценим модель, построив кривые потерь и точности и сохраним полученные графики.

3. Апробация 
3.1. Решение на реальных данных 
Для тестирования модели необходимы данные. Наиболее быстрым способом загрузить большое количество изображений одежды является использование Bing Image Search API . Реализацию процесса можно увидеть в приложении search_bing_api.py. 
В конечном результате были получены следующие данные: Блузы и рубашки (201 шт.); Брюки  ( шт.);  Верхняя одежда  (166 шт.);  Джемперы, свитеры и кардиганы (191 шт.);  Джинсы  (198 шт.);  Комбинезоны (192 шт.);   Купальники и пляжная одежда  (222 шт.);  Нижнее белье (209 шт.);   Носки, чулки и колготки  (220 шт.);  Пиджаки и костюмы (226 шт.);   Платья и сарафаны (234 шт.); Толстовки и свитшоты  (163 шт.);  Топы и майки  (102 шт.);  Туники  (213 шт.);  Футболки и поло  (203 шт.);  Шорты (217 шт.);   Юбки (192 шт.);  
В качестве примеров работы обученной модели загрузим еще 13 изображений из тех же источников.
Таким образом директория, содержащая все необходимые данные, будет представлена в виде:
├── dataset
│ ├── dress
│ ├── jackets
│ ├── jeans
│ ├── Jumpers
│ ├── outerwear
│ ├── overalls
│ ├── shirts
│ ├── shorts
│ ├── skirt
│ ├── socks
│ ├── sweatshirts
│ ├── swimwear
│ ├── top
│ ├── trousers
│ ├── t-shirt
│ ├── tunic
│ └── outerwear
├── examples 
├── model
│ ├── __init__.py
│ └── svggnet.py
├── plot.png
├── lb.pickle
├── clothes_classification.model
├── classify.py
├── search_bing_api.py
└── train.py

Рис.3 Схема директории проекта
Обучив модель на приведенных выше данных, можно перейти к классификации изображений, которые не принимали участие в обучении. Их мы загрузили в количестве 13 штук в папку Examples.
В новом скрипте для классификации мы загрузим необходимые библиотеки и запросим в качестве аргументов путь к обученной модели, бинаризатору меток и к входным изображениям.
Загрузив модель и бинаризатор меток, мы переходим к обработке считанного изображения. Так же, как и ранее, мы приводим их к требуемому размеру и конвертируем в массив NumPy для дальнейшей работы. Теперь мы можем классифицировать изображение методом model.predict() и создать метку опознанного изображения. 
Если метка изображения совпадает с меткой указанной нами в названии данного изображения, то предсказание подтверждается, в ином случае мы считаем предсказание неверным. 
Далее укажем на фотографии результаты теста и перейдем к их оценке.

3.2. Полученные результаты 
Обучив модель на реальных данных получены следующие результаты:
Точность на обучающей выборке 81,13%, а на тренировочной выборке 59,05%.
После использования данной модели на изображеиях вне обучающего массива мы получили описанные ниже результаты.
Классификатор прекрасно справился с пиджаком, джинсами, носками, комбинезонами, футболками, топом, купальниками и нижним бельем. Все результаты показали вероятность верноподобранной котегории свыше 80%
   
Рис.4,5,6. Результаты  классификации пиджака, джинс, носков.
   
Рис.7,8,9. Результаты классификации комбинезона, футболки 1, футболки 2
    
Рис.10,11,12. Результаты классификации топа, купальника и нижнего белья.
Платье, туника и свитшот оказались тоже корректно распознанными, однако при этом вероятность составила от 23 до 50%:
   
Рис. 13,14,15. Результаты классификации платья, туники, свитшота.
К сожалению в имеющемся наборе примеров имеются также распознанные неверно предметы одежды. Таковыми в нашем случае являются джемпер и рубашка. Джемпер был распознан на 59% как свитшот, а рубашка на 76% как джемпер.
   
Рис. 16,17. Результаты классификации джемпера и рубашки

3.3. Анализ имеющихся результатов 
Большую часть предметов одежды модель с легкостью смогла корректно классифицировать, однако встретились и категории, явно противоречащие выводам сверточной нейронной сети.
Добавив еще одну рубашку, было выявлено, что рубашки распознавать модель все же умеет. Исходя из этого можно сделать вывод о том, что модель распознает предметы одежды, однако не всегда так точно, как хотелось бы. Это так же можно увидеть в полученных результатах при обучении модели. Точность на тренировочной выборке составила 59%, что является недостаточным результатом для использования в реальных условиях. 
Для исправления имеющихся результатов оптимальным решением являются увеличение выборки для обучения модели и корректировка имеющихся параметров. При обучении на более большой выборке, модель с большей вероятностью сможет найти отличия джемпера от свитшота, а рубашки от джемпера. 

Заключение 
Таким образом, в своей работе нам удалось создать модель сверточной нейронной сети для распознавания предметов одежды на фотографиях. Обучение модели происходило на данных предоставляемых открытым Bing Search Image API, который является частью Microsoft’s Cognitive Services. Затем мы протестировали эту модель на фотографиях, не входивших в датасет обучения. Все это дало нам важную информацию о дальнейших шагах при развитии в данном направлении. Улучшив параметры модели и увеличив обучающую выборку, мы сможем с более высокой точностью определять представленный на фотографии товар, что поспособствует использованию полученной модели в более сложных проектах, нацеленных на повседневное потребление.
Список использованных источников 
	Тимяшева Е. Т. ТЕНДЕНЦИИ РАЗВИТИЯ FASHION-РИТЕЙЛА //Новая наука: Опыт, традиции, инновации. – 2017. – Т. 1. – №. 4. – С. 184-186.
	Вежневец А. П. Методы классификации с обучением по прецедентам в задаче распознавания объектов на изображениях //Международная конференция компьютерной графики и зрения [Электронный ресурс].-URL: http://graphicon. ru/html/2006/proceedings/papers/fr10_34_VezhnevetsA. pdf (дата обращения: 13.02. 2018). – 2006.
	Воронцов К. В. Лекции по статистическим (байесовским) алгоритмам классификации //Bayes. pdf. – 2008.
	Osuna E., Freund R., Girosit F. Training support vector machines: an application to face detection //Proceedings of IEEE computer society conference on computer vision and pattern recognition. – IEEE, 1997. – С. 130-136.
	Шмиг А. CS231n: Свёрточные нейронные сети для распознавания образов. 18/06/2019. [Электронный ресурс].-URL: https://habr.com/ru/post/456186/
	Блог компании Рег.ру Как начать работу с Keras, Deep Learning и Python Апрель 12, 2019 [Электронный ресурс].-URL: https://www.reg.ru/blog/keras/ 
	[Электронный ресурс].-URL: https://azure.microsoft.com/en-us/services/cognitive-services/bing-image-search-api/
